# AI Lecturer System - Project Status

## ğŸ“‹ Project Overview

An autonomous AI lecturer system that ingests PDF lecture slides, builds global understanding of the entire lecture, and generates context-aware pedagogical narration for each slide. The system converts narration to audio and provides a playback interface with auto-advancing slides.

**Key Innovation**: Global comprehension BEFORE narration generation â†’ ensures narrative continuity and pedagogical coherence.

---

## âœ… Completed Features

### Phase 1: Slide Ingestion & Parsing âœ“

**Status**: COMPLETE and TESTED

**What Works**:
- âœ… PDF parsing with per-page text extraction (PyMuPDF)
- âœ… Special academic content extraction (11 content types):
  - Definitions, Theorems, Corollaries, Lemmas, Propositions
  - Properties, Proofs, Examples, Remarks, Axioms, Claims
- âœ… Multi-line content capture with lookahead patterns
- âœ… False positive filtering (references vs actual content)
- âœ… Image extraction from PDFs with base64 encoding
- âœ… Bullet point and body text extraction
- âœ… Slide type classification

**Files**:
- `app/services/parsers/pdf_parser.py` - Main PDF parsing logic
- `app/models/slide.py` - Data models (SlideContent, SpecialContent, ImageContent)
- `test_parse.py` - Parser testing script

**Test Results**: Successfully parsed 135-slide Linear Optimization PDF with 112 special content items extracted.

**Known Issues Fixed**:
- âœ… Page splitting bug (pymupdf4llm returning all pages as one chunk)
- âœ… Special content truncation (regex only capturing first line)
- âœ… False positive references being captured as definitions/theorems

---

### Phase 2: Global Context Building âœ“

**Status**: COMPLETE and TESTED

**What Works**:
- âœ… Model-agnostic AI provider architecture (abstract base class)
- âœ… Three AI provider implementations:
  - GeminiProvider (gemini-2.5-flash) - FREE tier, used for prototyping
  - ClaudeProvider (claude-sonnet-4.5) - Premium quality (not yet tested due to cost)
  - DeepSeekProvider (deepseek-chat) - Budget option (implemented, not tested)
- âœ… Structural analysis (sections, topics, learning objectives, terminology)
- âœ… Vision analysis for diagrams and images
- âœ… Cross-reference extraction with robust parsing (handles multiple formats)
- âœ… Global plan synthesis
- âœ… Token usage tracking

**Files**:
- `app/services/global_context_builder.py` - Orchestrates analysis
- `app/services/ai/gemini_provider.py` - Gemini implementation
- `app/services/ai/claude_provider.py` - Claude implementation
- `app/services/ai/deepseek_provider.py` - DeepSeek implementation
- `app/services/ai/base.py` - Abstract AIProvider interface
- `app/models/global_plan.py` - GlobalContextPlan data model
- `test_gemini.py` - End-to-end testing script

**Test Results**: Successfully analyzed 135-slide deck with Gemini 2.5 Flash (FREE tier).

**Known Issues Fixed**:
- âœ… Cross-reference string format ("Slide 5" â†’ extract digits)
- âœ… Float cross-references (1.1, 2.8 â†’ convert to int)
- âœ… Complex reference strings ("Section 1.4" â†’ extract first number)
- âœ… LaTeX in prompts causing Python syntax errors

---

### Phase 3: Narration Generation âœ“

**Status**: COMPLETE and TESTED

**What Works**:
- âœ… Per-slide narration with full global context
- âœ… Previous narration summary for continuity
- âœ… Privacy-safe output (no instructor names, universities)
- âœ… TTS-compatible output (all LaTeX converted to spoken form)
- âœ… Pedagogical quality (conversational, explanatory, not verbatim)
- âœ… Token usage tracking per narration
- âœ… Request quota monitoring

**Files**:
- All AI providers have `generate_narration()` method
- `test_gemini.py` - Generates sample narrations

**Test Results**: Successfully generated 5 narrations with Gemini 2.5 Flash.

**Narration Quality Requirements**:
1. âœ… NO personal information (instructor names, universities)
2. âœ… Generic and reusable phrasing
3. âœ… ALL LaTeX converted to spoken form (no backslash syntax)
4. âœ… Conversational and pedagogical tone
5. âœ… Reference prior material when appropriate
6. âœ… Prepare learner for what's next
7. âœ… Non-redundant across slides

**Known Issues Fixed**:
- âœ… Personal info appearing in narrations (added strict privacy rules)
- âœ… LaTeX syntax in output (added conversion requirements to prompts)

---

### Phase 4: Text-to-Speech âœ“

**Status**: COMPLETE and TESTED

**What Works**:
- âœ… Edge TTS integration (FREE Microsoft TTS service)
- âœ… Multiple voice options (male/female, US/UK accents)
- âœ… MP3 audio file generation
- âœ… Async audio generation for performance
- âœ… No API key required

**Files**:
- `app/services/tts/edge_tts_provider.py` - Edge TTS implementation
- `app/services/tts/base.py` - Abstract TTS interface
- `test_tts.py` - TTS testing script

**Available Voices**:
- `en-US-GuyNeural` (Male US - default)
- `en-US-JennyNeural` (Female US)
- `en-GB-RyanNeural` (Male UK)
- `en-GB-SoniaNeural` (Female UK)

**Test Results**: Successfully generated MP3 audio from test narration (34.7 KB for 12 words).

---

### Phase 5: Narration Caching âœ“

**Status**: COMPLETE and TESTED

**What Works**:
- âœ… JSON-based caching system
- âœ… Stores narrations with slide indices
- âœ… Stores global plan alongside narrations
- âœ… Reusable across sessions (no AI regeneration needed)
- âœ… Automatic cache path generation from PDF name

**Files**:
- `app/services/narration_cache.py` - Caching implementation

**Cache Location**: `cache/narrations/{pdf_name}_narrations.json`

**Cache Format**:
```json
{
  "pdf_name": "Linear Optimization",
  "narrations": {
    "0": "narration text...",
    "1": "narration text...",
    ...
  },
  "global_plan": { ... }
}
```

---

## ğŸš§ Pending Features

### Phase 6: Slide Viewer with Audio Playback

**Status**: NOT STARTED

**What Needs to Be Built**:
- Web interface to display slide content
- Audio player synchronized with slides
- Auto-advance to next slide when audio finishes
- Manual next/prev controls
- Progress indicator (current slide / total slides)
- Play/pause controls
- Optional: slide thumbnails sidebar
- Optional: speed control for audio playback

**Technology Stack** (from plan):
- Frontend: Next.js 14+ with App Router
- UI: shadcn/ui + Tailwind CSS
- State: Zustand or React Context
- API Communication: Server-Sent Events (SSE) for real-time updates

**Files to Create**:
- `frontend/app/viewer/[sessionId]/page.tsx` - Main viewer page
- `frontend/components/SlideViewer.tsx` - Slide display component
- `frontend/components/AudioPlayer.tsx` - Audio playback component
- `backend/app/api/viewer.py` - API endpoints for viewer

---

## ğŸ”§ Current Configuration

### AI Provider (Gemini 2.5 Flash - FREE)

**Model**: `gemini-2.5-flash`
**API Key**: Stored in `.env` (GEMINI_API_KEY)
**Free Tier**: 1,500 requests/day
**Cost**: $0.00

**Usage Estimates**:
- Analysis: 1 request per lecture
- Vision: 1 request per lecture (if images present)
- Narration: 1 request per slide

For a 50-slide lecture:
- Total requests: ~52 (1 analysis + 1 vision + 50 narrations)
- Can process ~28 full lectures per day on free tier

### Environment Variables (.env)

```bash
AI_PROVIDER=gemini
GEMINI_API_KEY=AIzaSyBytri0Lcpg-kw8gukPcyuPUz0R7adhl-c
GEMINI_MODEL=gemini-2.5-flash
```

### Python Environment

- **Python Version**: 3.11 (in venv)
- **Virtual Environment**: `venv/` (activate with `source venv/bin/activate`)
- **Dependencies**: See `requirements.txt`

---

## ğŸ“ Project Structure

```
backend/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”œâ”€â”€ slide.py               # SlideContent, SpecialContent, ImageContent
â”‚   â”‚   â”œâ”€â”€ global_plan.py         # GlobalContextPlan, NarrationSegment
â”‚   â”‚   â””â”€â”€ session.py             # LectureSession (not yet used)
â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â”œâ”€â”€ parsers/
â”‚   â”‚   â”‚   â”œâ”€â”€ base.py            # Abstract parser interface
â”‚   â”‚   â”‚   â””â”€â”€ pdf_parser.py      # PDF parsing implementation
â”‚   â”‚   â”œâ”€â”€ ai/
â”‚   â”‚   â”‚   â”œâ”€â”€ base.py            # Abstract AIProvider
â”‚   â”‚   â”‚   â”œâ”€â”€ gemini_provider.py # Gemini implementation âœ“
â”‚   â”‚   â”‚   â”œâ”€â”€ claude_provider.py # Claude implementation
â”‚   â”‚   â”‚   â””â”€â”€ deepseek_provider.py # DeepSeek implementation
â”‚   â”‚   â”œâ”€â”€ tts/
â”‚   â”‚   â”‚   â”œâ”€â”€ base.py            # Abstract TTS interface
â”‚   â”‚   â”‚   â””â”€â”€ edge_tts_provider.py # Edge TTS implementation âœ“
â”‚   â”‚   â”œâ”€â”€ global_context_builder.py # Phase 2 orchestration âœ“
â”‚   â”‚   â””â”€â”€ narration_cache.py     # Caching system âœ“
â”‚   â”œâ”€â”€ api/                       # FastAPI endpoints (not yet implemented)
â”‚   â””â”€â”€ config.py                  # Settings configuration
â”œâ”€â”€ cache/
â”‚   â””â”€â”€ narrations/                # JSON cache files (currently empty)
â”œâ”€â”€ output/
â”‚   â””â”€â”€ audio/                     # Generated MP3 files
â”‚       â””â”€â”€ slide_000.mp3          # Test audio file âœ“
â”œâ”€â”€ test_parse.py                  # Test PDF parsing
â”œâ”€â”€ test_gemini.py                 # Test full pipeline with Gemini
â”œâ”€â”€ test_tts.py                    # Test TTS audio generation
â”œâ”€â”€ requirements.txt               # Python dependencies
â””â”€â”€ .env                           # Environment variables

frontend/                          # NOT YET CREATED
```

---

## ğŸ¯ How to Use (Current State)

### 1. Parse a PDF

```bash
source venv/bin/activate
python test_parse.py "/path/to/your/lecture.pdf"
```

**Output**: Displays parsed slides with titles, bullet points, special content, and images.

### 2. Generate Narrations (Full Pipeline)

```bash
source venv/bin/activate
python test_gemini.py "/path/to/your/lecture.pdf" --num-narrations 5
```

**What it does**:
1. Parses PDF slides
2. Builds global context with Gemini 2.5 Flash
3. Generates narrations for first 5 slides
4. Displays analysis results, token usage, and sample narrations
5. **Automatically caches narrations** to `cache/narrations/`

**Output**: Comprehensive analysis report + cached narrations

### 3. Generate Audio from Cached Narrations

```bash
source venv/bin/activate
python test_tts.py
```

**What it does**:
1. Loads cached narrations from `cache/narrations/Linear Optimization_narrations.json`
2. Generates MP3 audio files for first 5 slides
3. Saves to `output/audio/slide_000.mp3`, `slide_001.mp3`, etc.

**Note**: You must run `test_gemini.py` first to generate and cache narrations.

---

## âš ï¸ Known Limitations

### Model Compatibility

- **Gemini models**: Many have no free tier as of December 2025
  - âŒ `gemini-2.0-flash-exp` - limit 0 (no free tier)
  - âŒ `gemini-1.5-flash` - 404 not found
  - âŒ `gemini-2.0-flash` - limit 0
  - âŒ `gemini-2.5-flash-lite` - only 20 requests/day (exhausts quickly)
  - âœ… `gemini-2.5-flash` - WORKING free tier (1,500 req/day)

- **google.generativeai package**: Deprecated
  - Shows FutureWarning to switch to `google.genai`
  - Still works but will need migration eventually

### Parser Limitations

- Only supports PDF (not PPTX) - but you can convert PPTX to PDF first
- Scanned PDFs without OCR may have poor text extraction
- Complex PDF layouts may cause extraction issues
- Embedded videos/animations cannot be extracted

### Cost Considerations

- Using Gemini 2.5 Flash (free) for prototyping
- Claude Opus/Sonnet not tested yet (expensive - ~$1-6 per 50-slide lecture)
- DeepSeek not tested yet (cheap option)

---

## ğŸ› Issues Fixed

### Critical Bugs Resolved

1. **Page Splitting Bug** (Dec 2025)
   - **Problem**: pymupdf4llm returned all 135 pages as one chunk
   - **Fix**: Changed to per-page extraction with `page.get_text("text")`

2. **Special Content Truncation** (Dec 2025)
   - **Problem**: Regex only captured first line of definitions/theorems
   - **Fix**: Changed from `.+?` to `[\s\S]+?` with lookahead patterns

3. **False Positive References** (Dec 2025)
   - **Problem**: "Corollary 2.4 implies..." captured as actual corollary
   - **Fix**: Added filter for reference words (implies, shows, states, etc.)

4. **Cross-Reference Parsing Errors** (Dec 2025)
   - **Problem**: Gemini returned "Slide 5", floats, "Section 1.4"
   - **Fix**: Regex-based extraction to handle all formats

5. **LaTeX in Prompts** (Dec 2025)
   - **Problem**: Python interpreted `\mathbb{R}` as code
   - **Fix**: Escaped all backslashes: `\\mathbb{{R}}`

6. **Personal Info in Narrations** (Dec 2025)
   - **Problem**: Narrations mentioned instructor names and universities
   - **Fix**: Added strict privacy requirements to all provider prompts

7. **LaTeX in Narration Output** (Dec 2025)
   - **Problem**: Narrations contained LaTeX syntax (not TTS-compatible)
   - **Fix**: Added LaTeX-to-speech conversion requirements to prompts

---

## ğŸš€ Next Steps

### Immediate (Before Building Frontend)

1. **Test with Your PDF**:
   - Get a PDF lecture file
   - Run `test_gemini.py` to generate and cache narrations
   - Run `test_tts.py` to generate audio files
   - Verify audio quality and narration accuracy

2. **Verify Cache System**:
   - Confirm narrations are cached correctly
   - Test loading from cache in subsequent runs
   - Check that global plan is preserved

### Next Phase (Slide Viewer)

3. **Build Frontend**:
   - Set up Next.js project in `frontend/` directory
   - Create basic slide viewer component
   - Integrate audio player with auto-advance
   - Add manual navigation controls

4. **Backend API**:
   - Create FastAPI endpoints for serving slides and audio
   - Implement session management
   - Add Server-Sent Events for real-time updates

5. **Integration**:
   - Connect frontend to backend API
   - Test end-to-end flow: upload â†’ process â†’ view
   - Polish UI/UX

### Future Enhancements

- Multi-language support
- Custom voice selection in UI
- Narration editing and regeneration
- Export to video format (slides + audio)
- Database persistence (replace session-only storage)
- User accounts and lecture libraries
- Audience level customization per lecture
- Mobile-responsive viewer

---

## ğŸ“Š Performance Metrics

### Processing Speed (135-slide PDF)

- **Parsing**: ~2 seconds
- **Global Context Building**: ~30-40 seconds
- **Narration per Slide**: ~10-15 seconds (can parallelize)
- **Total for 5 slides**: ~3 minutes

### Token Usage (Gemini 2.5 Flash)

**Analysis Phase**:
- Input: ~15,000-25,000 tokens (varies by deck size)
- Output: ~3,000-5,000 tokens
- Cost: $0.00 (free tier)

**Narration Phase** (per slide):
- Input: ~2,000-4,000 tokens (global context + slide content)
- Output: ~200-400 tokens (narration text)
- Cost: $0.00 (free tier)

### File Sizes

- **Cached narrations**: ~50-100 KB per lecture (JSON)
- **Audio per slide**: ~30-50 KB (MP3, 1-2 min spoken)
- **Total audio for 50 slides**: ~1.5-2.5 MB

---

## ğŸ’¡ Tips & Best Practices

### For PDF Preparation

- Use native PDFs (not scanned images) for best text extraction
- Convert PPTX to PDF before processing
- Ensure diagrams are high quality (vision analysis depends on clarity)
- Include speaker notes if available (parser extracts them)

### For Narration Quality

- Provide clear, structured slide content
- Use standard academic formatting (Definition 1.2, Theorem 3.4)
- Include section headers for better context understanding
- Add relevant diagrams/images (Gemini uses them in narration)

### For Cost Management

- Use Gemini 2.5 Flash (free) for prototyping and testing
- Cache narrations to avoid regenerating them
- Monitor request quota daily (1,500 limit on free tier)
- Upgrade to Claude/DeepSeek only when ready for production

### For Development

- Always activate venv before running scripts
- Check cache directory before running TTS tests
- Review narrations for quality before generating audio
- Keep PDF files outside git repository (use .gitignore)

---

## ğŸ†˜ Troubleshooting

### "No module named 'edge_tts'"

```bash
source venv/bin/activate
pip install edge-tts
```

### "No cached narrations found"

Run `test_gemini.py` first to generate and cache narrations:

```bash
python test_gemini.py "/path/to/lecture.pdf" --num-narrations 5
```

### "Building wheel for pydantic-core failed"

Activate venv (Python 3.11) instead of using system Python (3.13):

```bash
source venv/bin/activate
pip install -r requirements.txt
```

### "GEMINI_API_KEY not found"

Add your API key to `.env`:

```bash
GEMINI_API_KEY=your_api_key_here
```

Get a free API key at: https://makersuite.google.com/app/apikey

### Narrations contain LaTeX syntax

This was fixed in the prompts. If you still see it:
1. Update `app/services/ai/gemini_provider.py` to latest version
2. Clear cache and regenerate narrations

### Narrations mention instructor names

This was fixed in the prompts. If you still see it:
1. Update all AI provider files to include privacy rules
2. Clear cache and regenerate narrations

---

## ğŸ“ Development History

### Session 1 (December 2025)

**Achievements**:
- âœ… Set up project structure (backend scaffolding)
- âœ… Implemented PDF parser with special content extraction
- âœ… Fixed page splitting bug
- âœ… Fixed special content truncation bug
- âœ… Fixed false positive reference filtering
- âœ… Implemented model-agnostic AI provider architecture
- âœ… Integrated Gemini 2.5 Flash (FREE tier)
- âœ… Implemented global context builder
- âœ… Fixed cross-reference parsing issues
- âœ… Added privacy and TTS compatibility to narration prompts
- âœ… Implemented Edge TTS integration
- âœ… Created narration caching system
- âœ… Tested end-to-end pipeline with sample PDF

**Key Decisions Made**:
- Use Gemini 2.5 Flash for free prototyping (not Claude/DeepSeek initially)
- Drop PPTX support (just convert to PDF first)
- Use Edge TTS instead of paid TTS services
- Implement caching to avoid regenerating narrations
- Model-agnostic architecture for easy provider swapping

**Testing Status**:
- âœ… PDF parsing tested and working (135 slides, 112 special content items)
- âœ… Global context building tested and working (Gemini 2.5 Flash)
- âœ… Narration generation tested and working (5 sample narrations)
- âœ… TTS tested and working (1 sample audio file)
- âš ï¸ Caching tested but no actual lecture cached yet (empty cache directory)

**Where We Left Off**:
- TTS service implemented and tested with sample narration
- Cache system implemented but not yet used (no cached narrations exist)
- Ready to test full pipeline: generate narrations â†’ cache â†’ generate audio
- Next phase: Build slide viewer with audio playback

---

## ğŸ“ Academic Content Extraction

The parser can extract and categorize 11 types of special academic content:

1. **Definition** - Formal concept definitions
2. **Theorem** - Mathematical theorems
3. **Corollary** - Corollaries of theorems
4. **Lemma** - Supporting lemmas
5. **Proposition** - Mathematical propositions
6. **Property** - Properties of mathematical objects
7. **Proof** - Formal proofs
8. **Example** - Worked examples
9. **Remark** - Important remarks or notes
10. **Axiom** - Fundamental axioms
11. **Claim** - Mathematical claims

Each extracted item includes:
- Content type
- Number/label (e.g., "2.1", "3.26")
- Title (if present)
- Full content text
- Source slide index

This enables the AI to provide more accurate and contextual narration for academic lectures.

---

## ğŸ“ Support & Documentation

### Official Documentation Links

- **FastAPI**: https://fastapi.tiangolo.com/
- **PyMuPDF**: https://pymupdf.readthedocs.io/
- **Gemini API**: https://ai.google.dev/docs
- **Edge TTS**: https://github.com/rany2/edge-tts
- **Next.js**: https://nextjs.org/docs (for future frontend)

### Project-Specific Help

- See `test_*.py` files for usage examples
- Check `.env.example` for required environment variables
- Review data models in `app/models/` for expected structures
- Read inline comments in service files for implementation details

---

## ğŸ”‘ Key Takeaways

### What Makes This System Unique

1. **Global-First Approach**: Analyzes entire lecture BEFORE generating any narration
   - Ensures pedagogical continuity
   - Enables cross-references and callbacks
   - Maintains consistent terminology

2. **Academic Content Awareness**: Extracts and preserves special content (definitions, theorems, etc.)
   - Better context for AI narration
   - Faithful to academic structure
   - Proper citation and referencing

3. **Privacy-Safe & TTS-Ready**: Narrations are generic and reusable
   - No personal information leakage
   - Clean audio output (no LaTeX syntax)
   - Professional quality for any institution

4. **Model-Agnostic**: Easy to swap AI providers
   - Start cheap (Gemini free)
   - Scale to quality (Claude Sonnet/Opus)
   - Optimize cost (DeepSeek)

5. **Free to Prototype**: Entire pipeline costs $0 during development
   - Gemini 2.5 Flash (free analysis + narration)
   - Edge TTS (free audio generation)
   - No database costs (session-only storage)

---

## ğŸ“… Last Updated

**Date**: December 26, 2025
**Status**: Phase 1-5 Complete, Phase 6 (Viewer) Pending
**Next Session**: Test full pipeline with real PDF, then build slide viewer

---

**Ready to Continue?** ğŸš€

When you return to this project:
1. Review this document to understand current state
2. Get a PDF lecture file to test with
3. Run `test_gemini.py` to generate and cache narrations
4. Run `test_tts.py` to generate audio files
5. Start building the slide viewer frontend

**Questions or Issues?** Check the Troubleshooting section above or review the service implementation files for details.
